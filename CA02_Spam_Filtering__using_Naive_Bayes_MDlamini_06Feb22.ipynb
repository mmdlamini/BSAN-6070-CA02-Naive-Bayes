{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02_Spam_Filtering _using_Naive_Bayes_MDlamini_06Feb22.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####BSAN 6070 Machine Learning CA02 Spam Filtering Emails using Naive Bayes Classification\n",
        "####**06 Feb 2022**"
      ],
      "metadata": {
        "id": "xPtTN_FEKkAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Mfolozi Dlamini**"
      ],
      "metadata": {
        "id": "fxsDuXJSKOaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing the necessary **modules** and **packages**"
      ],
      "metadata": {
        "id": "a_CUpkSUKn16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import modules/packages\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "MlDAVqEhKeFt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Link Working Directories\n",
        "\n"
      ],
      "metadata": {
        "id": "xypCJEr1LA3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive to link the working directories\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BPl1S7PLGNT",
        "outputId": "7f3cd09f-59c4-4713-b078-6f6f268a6b59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#link the working directories\n",
        "test = '/content/drive/My Drive/Colab_Notebooks/test-mails'\n",
        "train = '/content/drive/My Drive/Colab_Notebooks/train-mails'"
      ],
      "metadata": {
        "id": "xbvhAZNJz60Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Define a function with **3000** most common words from all emails"
      ],
      "metadata": {
        "id": "AeVrCUykMIYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The purpose of this function is to build a dictionary of the most common 3000 words from all email content. First it adds all words and symbols in the dictionary. It then removes all non-alpha-numeric characters and any single character alpha-numeric characters. The dictionary is then shrunk keep only the most common 3000 words in the dictionary. The function returns the Dictionary.\n"
      ],
      "metadata": {
        "id": "lJaHJlejMQoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dictionary(root_dir):\n",
        "  all_words_list = []\n",
        "\n",
        "  #listing files from email folder(root_dir)]\n",
        "  emails_list = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for email in emails_list:\n",
        "    with open(email) as eml:\n",
        "        for line in eml:\n",
        "  #Splitting of the lines into individual words\n",
        "          indiv_words = line.split()\n",
        "  #Appending the individual words to a list\n",
        "          all_words_list += indiv_words\n",
        "  #Count the number of words within the list\n",
        "    dictn = Counter(all_words_list)\n",
        "  #Converting from count back to the list\n",
        "    list_to_eliminate = list(dictn)\n",
        "\n",
        "    for l in list_to_eliminate:\n",
        "      if l.isalpha() == False:\n",
        "  #Deletion of non-alphanumeric characters\n",
        "        del dictn[l]\n",
        "      elif len(l) == 1:\n",
        "  #Deletion of single-lettered words like 'a'\n",
        "        del dictn[l]\n",
        "  #Creation of the final dictionary with 3000 most common words from email\n",
        "    dictn = dictn.most_common(3000)\n",
        "    return dictn\n",
        "    "
      ],
      "metadata": {
        "id": "63quixZnMwyY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Defining a function which extracts feature columns and populates their values\n"
      ],
      "metadata": {
        "id": "UVctetAfRkrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####This function extracts feature columns and populates their values (Feature Matrix of 3000 comumns and rows equal to the number of email files). The function also analyzes the File Names of each email file and decides if it's a Spam or not based on the naming convention. Based on this the function also creates the Labelled Data Column. This function is used to extract the training dataset as well as the testing dataset and returns the Feature Dataset and the Label column."
      ],
      "metadata": {
        "id": "KoPGIVb4RrBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def features_extracted (email_dir):\n",
        "#List of all files from folder\n",
        "  email = [os.path.join(email_dir,doc) for doc in os.listdir(email_dir)]\n",
        "#Making a list to store 3000 most common words and the number of files\n",
        "  features_matrix = np.zeros((len(email),3000))\n",
        "#Making an empty set of lables for the length of the number of files respectively\n",
        "  labels_train = np.zeros(len(email))\n",
        "  counts = 1;\n",
        "  fileID = 0;\n",
        "#For loop via listed files\n",
        "  for e in email:\n",
        "    with open(e) as il:\n",
        "#Enumerating of the looped file\n",
        "      for i, line in enumerate(il):\n",
        "        if i ==2:\n",
        "#Splitting of lines into individual words\n",
        "          word = line.split()\n",
        "          for w in word:\n",
        "#Base wordID            \n",
        "            wordID = 0\n",
        "            for il, d in enumerate(dictn):\n",
        "              if d[0] == w:\n",
        "#Matching the looped word with the word from the dictionary\n",
        "                wordID = il\n",
        "#Counting the number of occurances in case of a match\n",
        "                features_matrix[fileID,wordID] = word.count(word)\n",
        "#Base EmailID (not being spam)\n",
        "      labels_train[fileID] = 0;\n",
        "      filepathTokens = e.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "#In case name of the file indicates training data to be a spam, the email gets reallocated\n",
        "        labels_train[fileID] = 1;\n",
        "#In case the file is marked as a spam, the variable wordcount is changed. This is to insinuate the occurance of the word in spam file.\n",
        "        counts = counts + 1\n",
        "#Creating new fileID(EmailID) for the following email\n",
        "      fileID = fileID + 1\n",
        "  return features_matrix, labels_train             "
      ],
      "metadata": {
        "id": "eZMg5yAPRuZr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Call the working directories again (as above)"
      ],
      "metadata": {
        "id": "BMnALtzXR4mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#link the working directories\n",
        "test = '/content/drive/My Drive/Colab_Notebooks/test-mails'\n",
        "train = '/content/drive/My Drive/Colab_Notebooks/train-mails'"
      ],
      "metadata": {
        "id": "Z_Pfn0BbSF7U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Accuracy scores for predicting labels."
      ],
      "metadata": {
        "id": "A6rKNsx-SJx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base dictonary for most common words utilizing the training set\n",
        "dictn = make_dictionary(train)\n",
        "\n",
        "#Extraction of the ID and the respective counts from the two sets (test, training)\n",
        "print (\"Reading and Processing Emails from Train and Test folders\")\n",
        "features_matrix, labels_train = features_extracted(train)\n",
        "test_features_matrix, labels_test = features_extracted(test)\n",
        "\n",
        "#Gauss Naive Bayes Model (This model accounts the words to be normally distributed and are independent of each other)\n",
        "gnb_model = GaussianNB()\n",
        "\n",
        "#Check the features\n",
        "print (\"Training Model using Gaussian Naive Bayes Algorithm .....\")\n",
        "gnb_model.fit(features_matrix, labels_train)\n",
        "print (\"Training Complete\")\n",
        "print (\"Testing Trained model in order to predict Test Data labels\")\n",
        "labels_predicted = gnb_model.predict(test_features_matrix)\n",
        "print (\"Completed Test Data classification.... printing now Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(labels_test, labels_predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DSPYVo6SIwR",
        "outputId": "3802cd90-c264-43a5-c7d2-743ab2f18f34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and Processing Emails from Train and Test folders\n",
            "Training Model using Gaussian Naive Bayes Algorithm .....\n",
            "Training Complete\n",
            "Testing Trained model in order to predict Test Data labels\n",
            "Completed Test Data classification.... printing now Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:489: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:490: RuntimeWarning: invalid value encountered in true_divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
          ]
        }
      ]
    }
  ]
}